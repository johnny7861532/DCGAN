{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnny7861532/DCGAN/blob/master/Copy_of_Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tcm5ontLwyZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2FK7a-bV_xSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cuda_enable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qOOp-K_q_5Dk",
        "colab_type": "code",
        "outputId": "968f6e59-6097-4839-e091-5503a33c6cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.cuda.FloatTensor(1)\n",
        "x.get_device()\n",
        "print (torch.cuda.is_available())\n",
        "print (torch.cuda.device_count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TzTZN9CZwsHa",
        "colab_type": "code",
        "outputId": "cd9d556c-6ebc-413a-ced7-5b418811a6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2383
        }
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as visutils\n",
        "from torch.autograd import Variable\n",
        "\n",
        "batch_size = 64\n",
        "image_size = 64\n",
        "\n",
        "transform = transforms.Compose([transforms.Scale((image_size,image_size)),transforms.ToTensor()\n",
        ",transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),])\n",
        "\n",
        "imgdataset = dataset.CIFAR10(root = './data1',download = True, transform = transform)\n",
        "dataloader = torch.utils.data.DataLoader(imgdataset,batch_size = batch_size,shuffle = True\n",
        "                                         ,num_workers = 2)\n",
        "\n",
        "#cake_data = dataset.ImageFolder('./data', transform=transform)\n",
        "#cake_dataloader = torch.utils.data.DataLoader(cake_data,batch_size = batch_size,shuffle = True\n",
        "#                                         ,num_workers = 2)\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0,0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        #orginal setting is (0.0,0.02) but (1.0.0.002) result is much better\n",
        "        m.weight.data.normal_(1.0,0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class G(nn.Module):\n",
        "    #when u start a class u will always need to init func\n",
        "    def __init__(self):\n",
        "        super(G,self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "                #100 is input tensor , 512 is output tensor, 4 is kernel size\n",
        "                #1 is stride and 0 is padding\n",
        "                #keras using Conv2DTranspose\n",
        "                nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),\n",
        "                nn.BatchNorm2d(512), \n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\n",
        "                nn.Tanh()\n",
        "                 )\n",
        "    # forward input data through ooutput\n",
        "    def forward(self,input):\n",
        "        output = self.main(input)\n",
        "        return output\n",
        "    \n",
        "#inital generator\n",
        "netG = G().cuda()\n",
        "netG.apply(weights_init)\n",
        "\n",
        "class D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(D,self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, 4, 2, 1,bias = False),\n",
        "                nn.LeakyReLU(0.2,inplace = True),\n",
        "                nn.Conv2d(64, 128, 4, 2, 1,bias = False),\n",
        "                nn.LeakyReLU(0.2,inplace = True),\n",
        "                nn.Conv2d(128, 256, 4, 2, 1,bias = False),\n",
        "                nn.LeakyReLU(0.2,inplace = True),\n",
        "                nn.Conv2d(256, 512, 4, 2, 1,bias = False),\n",
        "                nn.LeakyReLU(0.2,inplace = True),\n",
        "                nn.Conv2d(512,1,4,1,0, bias = False),\n",
        "                nn.Sigmoid()\n",
        "                \n",
        "                )\n",
        "    def forward(self,input):\n",
        "        output = self.main(input)\n",
        "        return output.view(-1)\n",
        "        \n",
        "netD = D().cuda()\n",
        "netD.apply(weights_init)   \n",
        "\n",
        "\n",
        "#training DCGAN\n",
        "#BCE == Binary cross entropy\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optD = optim.Adam(netD.parameters(),lr = 0.00004,betas = (0.5,0.999))\n",
        "optG = optim.Adam(netG.parameters(),lr = 0.0002,betas = (0.5,0.999))\n",
        "\n",
        "#set up epochs\n",
        "for epoch in range(1000):\n",
        "    for i, data in enumerate(dataloader ,0):\n",
        "        #first step: update the weight of NN of D\n",
        "        netD.zero_grad()\n",
        "        #second step: training the D with real image\n",
        "        real, _ = data\n",
        "        #pytorch only take torch variable so we need to using varible first\n",
        "        input  = Variable(real)\n",
        "        #because this is the real image that we need to tag this one as 1 \n",
        "        #represent the true image for training discrimiator\n",
        "        target = Variable(torch.ones(input.size()[0]))\n",
        "        output = netD(input.cuda())\n",
        "        #using crterion to cuculate the err from output and target\n",
        "        errD_real = criterion(output,target.cuda())\n",
        "        #third step: training the D with fake image\n",
        "        # we create an nosie for generating image, and also this parameter \n",
        "        # must be torch.Variable aslo\n",
        "        noise = Variable(torch.randn(input.size()[0],100,1,1))\n",
        "        #init the generate net\n",
        "        fake = netG(noise.cuda())\n",
        "        #mark the fake image as 0\n",
        "        target = Variable(torch.zeros(input.size()[0]))\n",
        "        #this just for the classifier so we don't update the netG, so we add\n",
        "        #detach()\n",
        "        output = netD(fake.detach())\n",
        "        errD_fake = criterion(output,target.cuda())\n",
        "        #backpropagation of the toal loss\n",
        "        # sum up totall error\n",
        "        errD = errD_real + errD_fake\n",
        "        #backward the error\n",
        "        errD.backward()\n",
        "        #apply SDG (adam)\n",
        "        optD.step()\n",
        "        \n",
        "        #set up the generator of nn\n",
        "        netG.zero_grad()\n",
        "        target = Variable(torch.ones(input.size()[0]))\n",
        "        #we need to update the weight so we don't need detach\n",
        "        output = netD(fake)\n",
        "        #calculate the error\n",
        "        errG = criterion(output,target.cuda())\n",
        "        errG.backward()\n",
        "        #update the weight\n",
        "        optG.step()\n",
        "        \n",
        "        #print the loss and the generate image\n",
        "        \n",
        "        \n",
        "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 1000, i, len(dataloader), errD.item(), errG.item()))\n",
        "        if i % 100 == 0:\n",
        "            visutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize = True)\n",
        "            fake = netG(noise.cuda())\n",
        "            visutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./results\", epoch), normalize = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data1/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 169533440/170498071 [00:37<00:00, 5084802.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0/1000][0/782] Loss_D: 1.3863 Loss_G: 0.6930\n",
            "[0/1000][1/782] Loss_D: 1.3911 Loss_G: 0.6763\n",
            "[0/1000][2/782] Loss_D: 1.3973 Loss_G: 0.6639\n",
            "[0/1000][3/782] Loss_D: 1.4037 Loss_G: 0.6536\n",
            "[0/1000][4/782] Loss_D: 1.4015 Loss_G: 0.6466\n",
            "[0/1000][5/782] Loss_D: 1.4002 Loss_G: 0.6419\n",
            "[0/1000][6/782] Loss_D: 1.3974 Loss_G: 0.6397\n",
            "[0/1000][7/782] Loss_D: 1.3907 Loss_G: 0.6377\n",
            "[0/1000][8/782] Loss_D: 1.3857 Loss_G: 0.6346\n",
            "[0/1000][9/782] Loss_D: 1.3878 Loss_G: 0.6311\n",
            "[0/1000][10/782] Loss_D: 1.3820 Loss_G: 0.6283\n",
            "[0/1000][11/782] Loss_D: 1.3760 Loss_G: 0.6253\n",
            "[0/1000][12/782] Loss_D: 1.3763 Loss_G: 0.6253\n",
            "[0/1000][13/782] Loss_D: 1.3743 Loss_G: 0.6265\n",
            "[0/1000][14/782] Loss_D: 1.3607 Loss_G: 0.6271\n",
            "[0/1000][15/782] Loss_D: 1.3431 Loss_G: 0.6281\n",
            "[0/1000][16/782] Loss_D: 1.3276 Loss_G: 0.6292\n",
            "[0/1000][17/782] Loss_D: 1.3124 Loss_G: 0.6291\n",
            "[0/1000][18/782] Loss_D: 1.3101 Loss_G: 0.6286\n",
            "[0/1000][19/782] Loss_D: 1.2971 Loss_G: 0.6271\n",
            "[0/1000][20/782] Loss_D: 1.2889 Loss_G: 0.6243\n",
            "[0/1000][21/782] Loss_D: 1.3016 Loss_G: 0.6192\n",
            "[0/1000][22/782] Loss_D: 1.2854 Loss_G: 0.6132\n",
            "[0/1000][23/782] Loss_D: 1.2900 Loss_G: 0.6076\n",
            "[0/1000][24/782] Loss_D: 1.2568 Loss_G: 0.6080\n",
            "[0/1000][25/782] Loss_D: 1.2638 Loss_G: 0.6184\n",
            "[0/1000][26/782] Loss_D: 1.2798 Loss_G: 0.6337\n",
            "[0/1000][27/782] Loss_D: 1.2108 Loss_G: 0.6529\n",
            "[0/1000][28/782] Loss_D: 1.1776 Loss_G: 0.6712\n",
            "[0/1000][29/782] Loss_D: 1.2257 Loss_G: 0.6832\n",
            "[0/1000][30/782] Loss_D: 1.1037 Loss_G: 0.6924\n",
            "[0/1000][31/782] Loss_D: 1.1146 Loss_G: 0.6962\n",
            "[0/1000][32/782] Loss_D: 1.0974 Loss_G: 0.6927\n",
            "[0/1000][33/782] Loss_D: 1.1377 Loss_G: 0.6782\n",
            "[0/1000][34/782] Loss_D: 1.1692 Loss_G: 0.6452\n",
            "[0/1000][35/782] Loss_D: 1.2904 Loss_G: 0.5797\n",
            "[0/1000][36/782] Loss_D: 1.4750 Loss_G: 0.4975\n",
            "[0/1000][37/782] Loss_D: 1.6443 Loss_G: 0.4385\n",
            "[0/1000][38/782] Loss_D: 1.6962 Loss_G: 0.4194\n",
            "[0/1000][39/782] Loss_D: 1.7135 Loss_G: 0.4342\n",
            "[0/1000][40/782] Loss_D: 1.6562 Loss_G: 0.4773\n",
            "[0/1000][41/782] Loss_D: 1.5412 Loss_G: 0.5411\n",
            "[0/1000][42/782] Loss_D: 1.4016 Loss_G: 0.6154\n",
            "[0/1000][43/782] Loss_D: 1.3052 Loss_G: 0.6887\n",
            "[0/1000][44/782] Loss_D: 1.2662 Loss_G: 0.7518\n",
            "[0/1000][45/782] Loss_D: 1.2271 Loss_G: 0.7932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r170500096it [00:50, 5084802.57it/s]                               "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0/1000][46/782] Loss_D: 1.2064 Loss_G: 0.8099\n",
            "[0/1000][47/782] Loss_D: 1.1964 Loss_G: 0.8123\n",
            "[0/1000][48/782] Loss_D: 1.1602 Loss_G: 0.8151\n",
            "[0/1000][49/782] Loss_D: 1.1366 Loss_G: 0.8138\n",
            "[0/1000][50/782] Loss_D: 1.0775 Loss_G: 0.8046\n",
            "[0/1000][51/782] Loss_D: 1.1066 Loss_G: 0.7760\n",
            "[0/1000][52/782] Loss_D: 1.1657 Loss_G: 0.7190\n",
            "[0/1000][53/782] Loss_D: 1.1754 Loss_G: 0.6537\n",
            "[0/1000][54/782] Loss_D: 1.2438 Loss_G: 0.6031\n",
            "[0/1000][55/782] Loss_D: 1.4000 Loss_G: 0.5716\n",
            "[0/1000][56/782] Loss_D: 1.3451 Loss_G: 0.5642\n",
            "[0/1000][57/782] Loss_D: 1.4286 Loss_G: 0.5685\n",
            "[0/1000][58/782] Loss_D: 1.3015 Loss_G: 0.5798\n",
            "[0/1000][59/782] Loss_D: 1.3305 Loss_G: 0.5880\n",
            "[0/1000][60/782] Loss_D: 1.2865 Loss_G: 0.5873\n",
            "[0/1000][61/782] Loss_D: 1.3244 Loss_G: 0.5809\n",
            "[0/1000][62/782] Loss_D: 1.3690 Loss_G: 0.5802\n",
            "[0/1000][63/782] Loss_D: 1.3503 Loss_G: 0.5838\n",
            "[0/1000][64/782] Loss_D: 1.3185 Loss_G: 0.5853\n",
            "[0/1000][65/782] Loss_D: 1.3141 Loss_G: 0.5827\n",
            "[0/1000][66/782] Loss_D: 1.3376 Loss_G: 0.5778\n",
            "[0/1000][67/782] Loss_D: 1.3681 Loss_G: 0.5832\n",
            "[0/1000][68/782] Loss_D: 1.3237 Loss_G: 0.5949\n",
            "[0/1000][69/782] Loss_D: 1.2982 Loss_G: 0.6137\n",
            "[0/1000][70/782] Loss_D: 1.2881 Loss_G: 0.6305\n",
            "[0/1000][71/782] Loss_D: 1.2759 Loss_G: 0.6434\n",
            "[0/1000][72/782] Loss_D: 1.2170 Loss_G: 0.6536\n",
            "[0/1000][73/782] Loss_D: 1.2269 Loss_G: 0.6557\n",
            "[0/1000][74/782] Loss_D: 1.2398 Loss_G: 0.6503\n",
            "[0/1000][75/782] Loss_D: 1.2379 Loss_G: 0.6450\n",
            "[0/1000][76/782] Loss_D: 1.2095 Loss_G: 0.6437\n",
            "[0/1000][77/782] Loss_D: 1.2050 Loss_G: 0.6351\n",
            "[0/1000][78/782] Loss_D: 1.2280 Loss_G: 0.6113\n",
            "[0/1000][79/782] Loss_D: 1.2894 Loss_G: 0.5795\n",
            "[0/1000][80/782] Loss_D: 1.3561 Loss_G: 0.5569\n",
            "[0/1000][81/782] Loss_D: 1.3764 Loss_G: 0.5557\n",
            "[0/1000][82/782] Loss_D: 1.3738 Loss_G: 0.5763\n",
            "[0/1000][83/782] Loss_D: 1.3713 Loss_G: 0.6090\n",
            "[0/1000][84/782] Loss_D: 1.2815 Loss_G: 0.6452\n",
            "[0/1000][85/782] Loss_D: 1.2905 Loss_G: 0.6701\n",
            "[0/1000][86/782] Loss_D: 1.2060 Loss_G: 0.6820\n",
            "[0/1000][87/782] Loss_D: 1.2295 Loss_G: 0.6717\n",
            "[0/1000][88/782] Loss_D: 1.2287 Loss_G: 0.6517\n",
            "[0/1000][89/782] Loss_D: 1.2328 Loss_G: 0.6237\n",
            "[0/1000][90/782] Loss_D: 1.2373 Loss_G: 0.5897\n",
            "[0/1000][91/782] Loss_D: 1.3325 Loss_G: 0.5557\n",
            "[0/1000][92/782] Loss_D: 1.4163 Loss_G: 0.5179\n",
            "[0/1000][93/782] Loss_D: 1.4203 Loss_G: 0.5042\n",
            "[0/1000][94/782] Loss_D: 1.4241 Loss_G: 0.5205\n",
            "[0/1000][95/782] Loss_D: 1.3554 Loss_G: 0.5568\n",
            "[0/1000][96/782] Loss_D: 1.3812 Loss_G: 0.6014\n",
            "[0/1000][97/782] Loss_D: 1.3615 Loss_G: 0.6447\n",
            "[0/1000][98/782] Loss_D: 1.2790 Loss_G: 0.6791\n",
            "[0/1000][99/782] Loss_D: 1.2791 Loss_G: 0.6983\n",
            "[0/1000][100/782] Loss_D: 1.2779 Loss_G: 0.6974\n",
            "[0/1000][101/782] Loss_D: 1.3239 Loss_G: 0.6859\n",
            "[0/1000][102/782] Loss_D: 1.3019 Loss_G: 0.6821\n",
            "[0/1000][103/782] Loss_D: 1.2773 Loss_G: 0.6957\n",
            "[0/1000][104/782] Loss_D: 1.2639 Loss_G: 0.7120\n",
            "[0/1000][105/782] Loss_D: 1.2753 Loss_G: 0.7243\n",
            "[0/1000][106/782] Loss_D: 1.2428 Loss_G: 0.7304\n",
            "[0/1000][107/782] Loss_D: 1.2560 Loss_G: 0.7203\n",
            "[0/1000][108/782] Loss_D: 1.2507 Loss_G: 0.7112\n",
            "[0/1000][109/782] Loss_D: 1.2359 Loss_G: 0.7100\n",
            "[0/1000][110/782] Loss_D: 1.2454 Loss_G: 0.7110\n",
            "[0/1000][111/782] Loss_D: 1.2577 Loss_G: 0.7112\n",
            "[0/1000][112/782] Loss_D: 1.2050 Loss_G: 0.7076\n",
            "[0/1000][113/782] Loss_D: 1.2146 Loss_G: 0.7003\n",
            "[0/1000][114/782] Loss_D: 1.2161 Loss_G: 0.6941\n",
            "[0/1000][115/782] Loss_D: 1.2488 Loss_G: 0.6859\n",
            "[0/1000][116/782] Loss_D: 1.2410 Loss_G: 0.6771\n",
            "[0/1000][117/782] Loss_D: 1.2447 Loss_G: 0.6695\n",
            "[0/1000][118/782] Loss_D: 1.2570 Loss_G: 0.6628\n",
            "[0/1000][119/782] Loss_D: 1.2388 Loss_G: 0.6618\n",
            "[0/1000][120/782] Loss_D: 1.2098 Loss_G: 0.6729\n",
            "[0/1000][121/782] Loss_D: 1.2287 Loss_G: 0.6834\n",
            "[0/1000][122/782] Loss_D: 1.1855 Loss_G: 0.6940\n",
            "[0/1000][123/782] Loss_D: 1.1384 Loss_G: 0.7064\n",
            "[0/1000][124/782] Loss_D: 1.0450 Loss_G: 0.7232\n",
            "[0/1000][125/782] Loss_D: 1.0973 Loss_G: 0.7329\n",
            "[0/1000][126/782] Loss_D: 1.1422 Loss_G: 0.7253\n",
            "[0/1000][127/782] Loss_D: 1.1819 Loss_G: 0.6921\n",
            "[0/1000][128/782] Loss_D: 1.3225 Loss_G: 0.6437\n",
            "[0/1000][129/782] Loss_D: 1.3518 Loss_G: 0.6226\n",
            "[0/1000][130/782] Loss_D: 1.3662 Loss_G: 0.6462\n",
            "[0/1000][131/782] Loss_D: 1.2921 Loss_G: 0.6843\n",
            "[0/1000][132/782] Loss_D: 1.2883 Loss_G: 0.6821\n",
            "[0/1000][133/782] Loss_D: 1.2841 Loss_G: 0.6636\n",
            "[0/1000][134/782] Loss_D: 1.2560 Loss_G: 0.6751\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
